{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":407317,"sourceType":"datasetVersion","datasetId":181273}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# import system libs\nimport os\nimport time\nimport random\nimport pathlib\nimport itertools\nfrom glob import glob\nfrom tqdm import tqdm_notebook, tnrange\n\n# import data handling tools\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nsns.set_style('darkgrid')\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom skimage.color import rgb2gray\nfrom skimage.morphology import label\nfrom skimage.transform import resize\nfrom sklearn.model_selection import train_test_split\nfrom skimage.io import imread, imshow, concatenate_images\n\n# import Deep learning Libraries\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.models import Model, load_model, save_model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam, Adamax\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.layers import Input, Activation, BatchNormalization, Dropout, Lambda, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate\n\n# Ignore Warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2025-08-24T11:26:34.536927Z","iopub.execute_input":"2025-08-24T11:26:34.537123Z","iopub.status.idle":"2025-08-24T11:26:50.541007Z","shell.execute_reply.started":"2025-08-24T11:26:34.537106Z","shell.execute_reply":"2025-08-24T11:26:50.540355Z"},"trusted":true,"_kg_hide-input":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# function to create dataframe\ndef create_df(data_dir):\n    images_paths = []\n    masks_paths = glob(f'{data_dir}/*/*_mask*')\n\n    for i in masks_paths:\n        images_paths.append(i.replace('_mask', ''))\n\n    df = pd.DataFrame(data= {'images_paths': images_paths, 'masks_paths': masks_paths})\n\n    return df\n\n# Function to split dataframe into train, valid, test\ndef split_df(df):\n    # create train_df\n    train_df, test_df = train_test_split(df, train_size= 0.8)\n\n\n    return train_df, test_df","metadata":{"execution":{"iopub.status.busy":"2025-08-24T11:27:33.031241Z","iopub.execute_input":"2025-08-24T11:27:33.031510Z","iopub.status.idle":"2025-08-24T11:27:33.036273Z","shell.execute_reply.started":"2025-08-24T11:27:33.031490Z","shell.execute_reply":"2025-08-24T11:27:33.035463Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_gens(df, aug_dict):\n    img_size = (256, 256)\n    batch_size = 8\n\n\n    img_gen = ImageDataGenerator(**aug_dict)\n    msk_gen = ImageDataGenerator(**aug_dict)\n\n    # Create general generator\n    image_gen = img_gen.flow_from_dataframe(df, x_col='images_paths', class_mode=None, color_mode='rgb', target_size=img_size,\n                                            batch_size=batch_size, save_to_dir=None, save_prefix='image', seed=1)\n\n    mask_gen = msk_gen.flow_from_dataframe(df, x_col='masks_paths', class_mode=None, color_mode='grayscale', target_size=img_size,\n                                            batch_size=batch_size, save_to_dir=None, save_prefix= 'mask', seed=1)\n\n    gen = zip(image_gen, mask_gen)\n\n    for (img, msk) in gen:\n        img = img / 255\n        msk = msk / 255\n        msk[msk > 0.5] = 1\n        msk[msk <= 0.5] = 0\n\n        yield (img, msk)","metadata":{"execution":{"iopub.status.busy":"2025-08-24T11:28:03.143235Z","iopub.execute_input":"2025-08-24T11:28:03.143795Z","iopub.status.idle":"2025-08-24T11:28:03.148955Z","shell.execute_reply.started":"2025-08-24T11:28:03.143773Z","shell.execute_reply":"2025-08-24T11:28:03.148224Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def unet(input_size=(256, 256, 3)):\n    inputs = Input(input_size)\n\n    # First DownConvolution / Encoder Leg will begin, so start with Conv2D\n    conv1 = Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\")(inputs)\n    bn1 = Activation(\"relu\")(conv1)\n    conv1 = Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\")(bn1)\n    bn1 = BatchNormalization(axis=3)(conv1)\n    bn1 = Activation(\"relu\")(bn1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(bn1)\n\n    conv2 = Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\")(pool1)\n    bn2 = Activation(\"relu\")(conv2)\n    conv2 = Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\")(bn2)\n    bn2 = BatchNormalization(axis=3)(conv2)\n    bn2 = Activation(\"relu\")(bn2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(bn2)\n\n    conv3 = Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\")(pool2)\n    bn3 = Activation(\"relu\")(conv3)\n    conv3 = Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\")(bn3)\n    bn3 = BatchNormalization(axis=3)(conv3)\n    bn3 = Activation(\"relu\")(bn3)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(bn3)\n\n    conv4 = Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\")(pool3)\n    bn4 = Activation(\"relu\")(conv4)\n    conv4 = Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\")(bn4)\n    bn4 = BatchNormalization(axis=3)(conv4)\n    bn4 = Activation(\"relu\")(bn4)\n    pool4 = MaxPooling2D(pool_size=(2, 2))(bn4)\n\n    conv5 = Conv2D(filters=1024, kernel_size=(3, 3), padding=\"same\")(pool4)\n    bn5 = Activation(\"relu\")(conv5)\n    conv5 = Conv2D(filters=1024, kernel_size=(3, 3), padding=\"same\")(bn5)\n    bn5 = BatchNormalization(axis=3)(conv5)\n    bn5 = Activation(\"relu\")(bn5)\n\n    \"\"\" Now UpConvolution / Decoder Leg will begin, so start with Conv2DTranspose\n    The gray arrows (in the above image) indicate the skip connections that concatenate the encoder feature map with the decoder, which helps the backward flow of gradients for improved training. \"\"\"\n    \"\"\" After every concatenation we again apply two consecutive regular convolutions so that the model can learn to assemble a more precise output \"\"\"\n\n    up6 = concatenate([Conv2DTranspose(512, kernel_size=(2, 2), strides=(2, 2), padding=\"same\")(bn5), conv4], axis=3)\n    conv6 = Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\")(up6)\n    bn6 = Activation(\"relu\")(conv6)\n    conv6 = Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\")(bn6)\n    bn6 = BatchNormalization(axis=3)(conv6)\n    bn6 = Activation(\"relu\")(bn6)\n\n    up7 = concatenate([Conv2DTranspose(256, kernel_size=(2, 2), strides=(2, 2), padding=\"same\")(bn6), conv3], axis=3)\n    conv7 = Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\")(up7)\n    bn7 = Activation(\"relu\")(conv7)\n    conv7 = Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\")(bn7)\n    bn7 = BatchNormalization(axis=3)(conv7)\n    bn7 = Activation(\"relu\")(bn7)\n\n    up8 = concatenate([Conv2DTranspose(128, kernel_size=(2, 2), strides=(2, 2), padding=\"same\")(bn7), conv2], axis=3)\n    conv8 = Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\")(up8)\n    bn8 = Activation(\"relu\")(conv8)\n    conv8 = Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\")(bn8)\n    bn8 = BatchNormalization(axis=3)(conv8)\n    bn8 = Activation(\"relu\")(bn8)\n\n    up9 = concatenate([Conv2DTranspose(64, kernel_size=(2, 2), strides=(2, 2), padding=\"same\")(bn8), conv1], axis=3)\n    conv9 = Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\")(up9)\n    bn9 = Activation(\"relu\")(conv9)\n    conv9 = Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\")(bn9)\n    bn9 = BatchNormalization(axis=3)(conv9)\n    bn9 = Activation(\"relu\")(bn9)\n\n    conv10 = Conv2D(filters=1, kernel_size=(1, 1), activation=\"sigmoid\")(bn9)\n\n    return Model(inputs=[inputs], outputs=[conv10])","metadata":{"execution":{"iopub.status.busy":"2025-08-24T11:28:11.507277Z","iopub.execute_input":"2025-08-24T11:28:11.507776Z","iopub.status.idle":"2025-08-24T11:28:11.522461Z","shell.execute_reply.started":"2025-08-24T11:28:11.507754Z","shell.execute_reply":"2025-08-24T11:28:11.521820Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# function to create dice coefficient\ndef dice_coef(y_true, y_pred, smooth=100):\n    y_true_flatten = K.flatten(y_true)\n    y_pred_flatten = K.flatten(y_pred)\n\n    intersection = K.sum(y_true_flatten * y_pred_flatten)\n    union = K.sum(y_true_flatten) + K.sum(y_pred_flatten)\n    return (2 * intersection + smooth) / (union + smooth)\n\n# function to create dice loss\ndef dice_loss(y_true, y_pred, smooth=100):\n    return -dice_coef(y_true, y_pred, smooth)\n\n# function to create iou coefficient\ndef iou_coef(y_true, y_pred, smooth=100):\n    intersection = K.sum(y_true * y_pred)\n    sum = K.sum(y_true + y_pred)\n    iou = (intersection + smooth) / (sum - intersection + smooth)\n    return iou","metadata":{"execution":{"iopub.status.busy":"2025-08-24T11:28:22.035261Z","iopub.execute_input":"2025-08-24T11:28:22.035502Z","iopub.status.idle":"2025-08-24T11:28:22.040599Z","shell.execute_reply.started":"2025-08-24T11:28:22.035485Z","shell.execute_reply":"2025-08-24T11:28:22.039810Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def show_images(images, masks):\n    plt.figure(figsize=(12, 12))\n    for i in range(25):\n        plt.subplot(5, 5, i+1)\n        img_path = images[i]\n        mask_path = masks[i]\n        # read image and convert it to RGB scale\n        image = cv2.imread(img_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        # read mask\n        mask = cv2.imread(mask_path)\n        # sho image and mask\n        plt.imshow(image)\n        plt.imshow(mask, alpha=0.4)\n\n        plt.axis('off')\n\n    plt.tight_layout()\n    plt.savefig('Images.png', dpi = 1200)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2025-08-24T14:20:21.337001Z","iopub.execute_input":"2025-08-24T14:20:21.337576Z","iopub.status.idle":"2025-08-24T14:20:21.342561Z","shell.execute_reply.started":"2025-08-24T14:20:21.337553Z","shell.execute_reply":"2025-08-24T14:20:21.341763Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_training(hist):\n    '''\n    This function take training model and plot history of accuracy and losses with the best epoch in both of them.\n    '''\n\n    # Define needed variables\n    tr_acc = hist.history['accuracy']\n    tr_iou = hist.history['iou_coef']\n    tr_dice = hist.history['dice_coef']\n    tr_loss = hist.history['loss']\n\n    val_acc = hist.history['val_accuracy']\n    val_iou = hist.history['val_iou_coef']\n    val_dice = hist.history['val_dice_coef']\n    val_loss = hist.history['val_loss']\n\n    index_acc = np.argmax(val_acc)\n    acc_highest = val_acc[index_acc]\n    index_iou = np.argmax(iou_coef)\n    iou_highest = val_iou[index_iou]\n    index_dice = np.argmax(dice_coef)\n    dice_highest = val_dice[index_dice]\n    index_loss = np.argmin(val_loss)\n    val_lowest = val_loss[index_loss]\n\n    Epochs = [i+1 for i in range(len(tr_acc))]\n\n    # Plot training history\n    plt.figure(figsize= (20, 20))\n    plt.style.use('fivethirtyeight')\n\n    # Training Accuracy\n    plt.subplot(2, 2, 1)\n    plt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')\n    plt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')\n    plt.title('Training and Validation Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend()\n\n    # Training IoU\n    plt.subplot(2, 2, 2)\n    plt.plot(Epochs, tr_iou, 'r', label= 'Training IoU')\n    plt.plot(Epochs, val_iou, 'g', label= 'Validation IoU')\n    plt.title('Training and Validation IoU Coefficient')\n    plt.xlabel('Epochs')\n    plt.ylabel('IoU')\n    plt.legend()\n\n    # Training Dice\n    plt.subplot(2, 2, 3)\n    plt.plot(Epochs, tr_dice, 'r', label= 'Training Dice')\n    plt.plot(Epochs, val_dice, 'g', label= 'Validation Dice')\n    plt.title('Training and Validation Dice Coefficient')\n    plt.xlabel('Epochs')\n    plt.ylabel('Dice')\n    plt.legend()\n\n    # Training Loss\n    plt.subplot(2, 2, 4)\n    plt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\n    plt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\n    plt.title('Training and Validation Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n\n    plt.tight_layout\n    plt.savefig('Acc_Loss.png', dpi=1200)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2025-08-24T14:02:19.422328Z","iopub.execute_input":"2025-08-24T14:02:19.422601Z","iopub.status.idle":"2025-08-24T14:02:19.432151Z","shell.execute_reply.started":"2025-08-24T14:02:19.422580Z","shell.execute_reply":"2025-08-24T14:02:19.431538Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Model Structure**","metadata":{}},{"cell_type":"markdown","source":"### **Start reading data**","metadata":{}},{"cell_type":"code","source":"data_dir = '/kaggle/input/lgg-mri-segmentation/kaggle_3m'\n\ndf = create_df(data_dir)\ntrain_df, test_df = split_df(df)\n\n\ntr_aug_dict = dict(rotation_range=0.2,\n                            width_shift_range=0.05,\n                            height_shift_range=0.05,\n                            shear_range=0.05,\n                            zoom_range=0.05,\n                            horizontal_flip=True,\n                            fill_mode='nearest')\n\n\ntrain_gen = create_gens(train_df, aug_dict=tr_aug_dict)\ntest_gen = create_gens(test_df, aug_dict={})\n\nshow_images(list(train_df['images_paths']), list(train_df['masks_paths']))","metadata":{"execution":{"iopub.status.busy":"2025-08-24T14:20:24.521300Z","iopub.execute_input":"2025-08-24T14:20:24.521577Z","iopub.status.idle":"2025-08-24T14:20:56.888966Z","shell.execute_reply.started":"2025-08-24T14:20:24.521555Z","shell.execute_reply":"2025-08-24T14:20:56.887965Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Unet Model**","metadata":{}},{"cell_type":"code","source":"model = unet()\nmodel.compile(Adamax(learning_rate= 0.0001), loss= dice_loss, metrics= ['accuracy', iou_coef, dice_coef])","metadata":{"execution":{"iopub.status.busy":"2025-08-24T11:30:59.393238Z","iopub.execute_input":"2025-08-24T11:30:59.393523Z","iopub.status.idle":"2025-08-24T11:31:01.725934Z","shell.execute_reply.started":"2025-08-24T11:30:59.393500Z","shell.execute_reply":"2025-08-24T11:31:01.725296Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Model training**","metadata":{}},{"cell_type":"code","source":"epochs = 100\nbatch_size = 8\ncallbacks = [ModelCheckpoint(filepath ='/kaggle/working/best_model.keras', monitor='dice_coef', mode = 'max', save_best_only=True)]\n\nhistory = model.fit(train_gen,\n                    steps_per_epoch=int(len(train_df) / batch_size),\n                    epochs=epochs,\n                    verbose=1,\n                    callbacks=callbacks,\n                    validation_data = test_gen,\n                    validation_steps=int(len(test_df) / batch_size))","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2025-08-24T11:34:35.824221Z","iopub.execute_input":"2025-08-24T11:34:35.824778Z","iopub.status.idle":"2025-08-24T14:01:24.687954Z","shell.execute_reply.started":"2025-08-24T11:34:35.824756Z","shell.execute_reply":"2025-08-24T14:01:24.686904Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_training(history)","metadata":{"execution":{"iopub.status.busy":"2025-08-24T14:02:26.620408Z","iopub.execute_input":"2025-08-24T14:02:26.620891Z","iopub.status.idle":"2025-08-24T14:02:58.449245Z","shell.execute_reply.started":"2025-08-24T14:02:26.620867Z","shell.execute_reply":"2025-08-24T14:02:58.448417Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Model Evaluation**","metadata":{}},{"cell_type":"code","source":"model.load_weights(filepath ='/kaggle/working/best_model.keras')\nmodel.compile(Adamax(learning_rate= 0.0001), loss= dice_loss, metrics= ['accuracy', iou_coef, dice_coef])\n\ntest_steps = int(len(test_df) / batch_size)\n\ntrain_score = model.evaluate(train_gen, steps= test_steps, verbose= 1)\ntest_score = model.evaluate(test_gen, steps= test_steps, verbose= 1)\n\n\nprint(\"Train Loss: \", train_score[0])\nprint(\"Train Accuracy: \", train_score[1])\nprint(\"Train IoU: \", train_score[2])\nprint(\"Train Dice: \", train_score[3])\nprint('-' * 20)\n\nprint(\"Test Loss: \", test_score[0])\nprint(\"Test Accuracy: \", test_score[1])\nprint(\"Test IoU: \", test_score[2])\nprint(\"Test Dice: \", test_score[3])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for _ in range(20):\n    index = np.random.randint(1, len(test_df.index))\n    img = cv2.imread(test_df['images_paths'].iloc[index])\n    img = cv2.resize(img, (256, 256))\n    img = img/255\n    img = img[np.newaxis, :, :, : ]\n\n    predicted_img = model.predict(img)\n\n    plt.figure(figsize=(12, 12))\n    \n    plt.subplot(1, 3, 1)\n    plt.imshow(np.squeeze(img))\n    plt.axis('off')\n    plt.title('Original Image')\n\n    plt.subplot(1, 3, 2)\n    plt.imshow(np.squeeze(cv2.imread(test_df['masks_paths'].iloc[index])))\n    plt.axis('off')\n    plt.title('Original Mask')\n\n    plt.subplot(1, 3, 3)\n    plt.imshow(np.squeeze(predicted_img) > 0.5 )\n    plt.title('Prediction')\n    plt.axis('off')\n    plt.savefig('Prediction.png', dpi=1200)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2025-08-24T14:08:52.142611Z","iopub.execute_input":"2025-08-24T14:08:52.142887Z","iopub.status.idle":"2025-08-24T14:12:08.704638Z","shell.execute_reply.started":"2025-08-24T14:08:52.142868Z","shell.execute_reply":"2025-08-24T14:12:08.703818Z"},"trusted":true},"outputs":[],"execution_count":null}]}